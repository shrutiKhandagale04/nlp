{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-10T05:05:11.890977Z",
     "start_time": "2024-09-10T05:05:10.647487Z"
    }
   },
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "text1 = [\"\"\"Gensim is a free open-source Python library for representing documents as semantic vectors,\n",
    "           as efficiently and painlessly as possible. Gensim is designed \n",
    "           to process raw, unstructured digital texts using unsupervised machine learning algorithms.\"\"\"]\n",
    "\n",
    "tokens1 = [[item for item in line.split()] for line in text1]\n",
    "g_dict1 = corpora.Dictionary(tokens1)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(g_dict1)) + \" tokens\\n\")\n",
    "print(g_dict1.token2id)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 29 tokens\n",
      "\n",
      "{'Gensim': 0, 'Python': 1, 'a': 2, 'algorithms.': 3, 'and': 4, 'as': 5, 'designed': 6, 'digital': 7, 'documents': 8, 'efficiently': 9, 'for': 10, 'free': 11, 'is': 12, 'learning': 13, 'library': 14, 'machine': 15, 'open-source': 16, 'painlessly': 17, 'possible.': 18, 'process': 19, 'raw,': 20, 'representing': 21, 'semantic': 22, 'texts': 23, 'to': 24, 'unstructured': 25, 'unsupervised': 26, 'using': 27, 'vectors,': 28}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:07:03.392173Z",
     "start_time": "2024-09-10T05:07:03.384411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora\n",
    "\n",
    "text2 = open('sample.txt', encoding ='utf-8')\n",
    " \n",
    "tokens2 =[]\n",
    "for line in text2.read().split('.'):\n",
    "  tokens2.append(simple_preprocess(line, deacc = True))\n",
    "\n",
    "g_dict2 = corpora.Dictionary(tokens2)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(g_dict2)) + \" tokens\\n\")\n",
    "print(g_dict2.token2id)"
   ],
   "id": "6edb38e9a887dba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 3 tokens\n",
      "\n",
      "{'khandagale': 0, 'laxman': 1, 'shruti': 2}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:08:50.384180Z",
     "start_time": "2024-09-10T05:08:50.380080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g_dict1.add_documents(tokens2)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(g_dict1)) + \" tokens\\n\")\n",
    "print(g_dict1.token2id)"
   ],
   "id": "35490c58e4016f73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 32 tokens\n",
      "\n",
      "{'Gensim': 0, 'Python': 1, 'a': 2, 'algorithms.': 3, 'and': 4, 'as': 5, 'designed': 6, 'digital': 7, 'documents': 8, 'efficiently': 9, 'for': 10, 'free': 11, 'is': 12, 'learning': 13, 'library': 14, 'machine': 15, 'open-source': 16, 'painlessly': 17, 'possible.': 18, 'process': 19, 'raw,': 20, 'representing': 21, 'semantic': 22, 'texts': 23, 'to': 24, 'unstructured': 25, 'unsupervised': 26, 'using': 27, 'vectors,': 28, 'khandagale': 29, 'laxman': 30, 'shruti': 31}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating Bag of Words",
   "id": "6c05ae7d9f5632bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:09:17.475087Z",
     "start_time": "2024-09-10T05:09:17.470610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g_bow =[g_dict1.doc2bow(token, allow_update = True) for token in tokens1]\n",
    "print(\"Bag of Words : \", g_bow)"
   ],
   "id": "b8828ffff604ec14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words :  [[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 3), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:09:52.556374Z",
     "start_time": "2024-09-10T05:09:52.551589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g_bow =[g_dict1.doc2bow(token, allow_update = True) for token in tokens1]\n",
    "print(\"Bag of Words : \", g_bow)"
   ],
   "id": "f80e4f7e24f689b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words :  [[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 3), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating a tf-idf",
   "id": "6aa903765b617e42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:13:17.616181Z",
     "start_time": "2024-09-10T05:13:17.604598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "text = [\"The food is excellent but the service can be better\",\n",
    "        \"The food is always delicious and loved the service\",\n",
    "        \"The food was mediocre and the service was terrible\"]\n",
    "\n",
    "g_dict = corpora.Dictionary([simple_preprocess(line) for line in text])\n",
    "g_bow = [g_dict.doc2bow(simple_preprocess(line)) for line in text]\n",
    "\n",
    "print(\"Dictionary : \")\n",
    "for item in g_bow:\n",
    "    print([[g_dict[id], freq] for id, freq in item])\n",
    "\n",
    "g_tfidf = models.TfidfModel(g_bow, smartirs='ntc')\n",
    "\n",
    "print(\"TF-IDF Vector:\")\n",
    "for item in g_tfidf[g_bow]:\n",
    "    print([[g_dict[id], np.around(freq, decimals=2)] for id, freq in item])"
   ],
   "id": "65cb77187233c15e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary : \n",
      "[['be', 1], ['better', 1], ['but', 1], ['can', 1], ['excellent', 1], ['food', 1], ['is', 1], ['service', 1], ['the', 2]]\n",
      "[['food', 1], ['is', 1], ['service', 1], ['the', 2], ['always', 1], ['and', 1], ['delicious', 1], ['loved', 1]]\n",
      "[['food', 1], ['service', 1], ['the', 2], ['and', 1], ['mediocre', 1], ['terrible', 1], ['was', 2]]\n",
      "TF-IDF Vector:\n",
      "[['be', 0.43], ['better', 0.43], ['but', 0.43], ['can', 0.43], ['excellent', 0.43], ['food', 0.09], ['is', 0.21], ['service', 0.09], ['the', 0.18]]\n",
      "[['food', 0.11], ['is', 0.26], ['service', 0.11], ['the', 0.21], ['always', 0.52], ['and', 0.26], ['delicious', 0.52], ['loved', 0.52]]\n",
      "[['food', 0.08], ['service', 0.08], ['the', 0.16], ['and', 0.2], ['mediocre', 0.39], ['terrible', 0.39], ['was', 0.78]]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Word to Vec Model ",
   "id": "8fda19657726633"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:16:54.331318Z",
     "start_time": "2024-09-10T05:16:32.290017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load the text8 dataset\n",
    "dataset = api.load(\"text8\")\n",
    "\n",
    "# Prepare the data (dataset is an iterator, we need a list of tokenized sentences)\n",
    "words = [d for d in dataset]\n",
    "\n",
    "# Use the first 1000 sentences\n",
    "data1 = words[:1000]\n",
    "\n",
    "# Train a Word2Vec model on the tokenized sentences\n",
    "w2v_model = Word2Vec(data1, min_count=1, workers=cpu_count())\n",
    "\n",
    "# Save the model\n",
    "w2v_model.save(\"word2vec_model_text8\")\n",
    "\n",
    "# Example: Getting vector for a word\n",
    "word_vector = w2v_model.wv['king']  # Example to get the word vector for 'king'\n",
    "\n",
    "# Display the word vector for 'king'\n",
    "print(word_vector)\n"
   ],
   "id": "f88c4bf77b4446ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.8031335  -0.21976678 -1.0846417   2.139007    0.15377729 -0.68191826\n",
      " -3.0022268  -0.62324005  2.070712   -0.88086414 -0.07410897  2.0458372\n",
      "  3.308508    1.2110171   3.9215193  -2.0003214   0.09288459  1.0773298\n",
      "  3.9262824  -1.0983424   1.2539767   1.1885593   0.84988713  2.74991\n",
      "  0.7938108   0.5388029   2.1001287  -2.819218    0.25290787  0.8201379\n",
      "  0.23509927 -2.1467423   0.05534726 -1.15489     2.4897785   1.8280953\n",
      "  1.5219172  -1.0381143  -0.44220635  0.7947314  -0.25239903 -0.62839824\n",
      "  0.48405114 -0.81509256  1.4324458  -3.7155836  -1.8690464  -3.19993\n",
      "  1.2248409   1.6176951   1.556343    2.2219458  -2.5986428  -3.190451\n",
      " -2.0061145   2.288872    3.3241117   0.41138983  0.60243815 -1.3466425\n",
      "  0.96312314  2.842241    0.3628329   0.51295614  0.5152199  -0.79482746\n",
      " -0.92165357 -1.2423123   0.14244322 -1.3210897   0.3068016   0.88770425\n",
      " -0.88662046 -1.2813677  -1.1594144   0.51025367  2.4039226  -1.1943753\n",
      " -1.5858489   0.7479321   1.6926975   1.8125972   0.734578    0.5767889\n",
      "  0.64147997  0.54543585  1.5676098   2.185719   -1.4027959   0.0252242\n",
      "  0.72254294  0.4663952  -3.4172823   0.7429195  -0.7685233   0.6766321\n",
      "  2.555894    0.25103644 -0.96355444 -1.4243913 ]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cec7f8d1a3f595c3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
